# Weighting 

## Surface forms 

An unannotated machine-readable text corpus of a language is usually fairly easy to come 
by... given the language has some kind of orthography. So, what can you use it for ? Well, you
could use it to arbitrate which form is better to generate in the case of having free variation.
For example, in Guaraní the *-сть* in Russian loanwords in the nominative singular 
can be written as *-ҫ* or *-сть*. 

One possibility would be to have a lexicon like:

```
LEXICON N/сть

%&lt;n%&gt;:ҫ SUBST "weight: 0.5" ;
%&lt;n%&gt;%&lt;nom%&gt;:сть # "weight: 1.0" ;
```

Which would always prefer the form with *-ҫ*. But perhaps it is lexicalised or depends on 
some other factors. Let's start by making a frequency list:

```
$ cat chv.crp.txt  | sed 's/[^а-яӑӗăĕҫçА-ЯӐӖĂĔҪÇ]\+/ /g' | tr ' ' '\n' | sort -f | uniq -c | sort -gr  &gt; chv.freq.txt
```

We can convert this frequency list into a format suitable for building a weighted transducer using 
the following Python code:

<pre style="margin: 0; line-height: 125%"><span style="color: #0000aa">import</span> <span style="color: #00aaaa; text-decoration: underline">sys</span>, <span style="color: #00aaaa; text-decoration: underline">math</span> <span style="color: #0000aa">as</span> <span style="color: #00aaaa; text-decoration: underline">maths</span>
f = {}; fs = []
total = <span style="color: #009999">0</span>
<span style="color: #0000aa">for</span> line <span style="color: #0000aa">in</span> sys.stdin.readlines():
	row = line.strip().split(<span style="color: #aa5500">&#39; &#39;</span>)
	<span style="color: #0000aa">if</span> <span style="color: #00aaaa">len</span>(row) &lt; <span style="color: #009999">2</span>: <span style="color: #0000aa">continue</span>
	form = row[<span style="color: #009999">1</span>]
	freq = <span style="color: #00aaaa">int</span>(row[<span style="color: #009999">0</span>])
	fs.append(form)
	f[form] = freq
	total += freq
<span style="color: #0000aa">for</span> form <span style="color: #0000aa">in</span> fs: 
	<span style="color: #0000aa">print</span>(<span style="color: #aa5500">&#39;%s\t%.4f&#39;</span> % (form, -maths.log(f[form]/total)))
</pre>

If we make a new file and save it as `freq2prob.py` we can call it on the command line as follows:

```
$ cat chv.freq.txt | python3 freq2prob.py | hfst-strings2fst -j -o chv.surweights.hfst
```

Check that it works:

```
$ echo "область" | hfst-lookup -qp chv.surweights.hfst
область	область	11,393500

$ echo "облаҫ" | hfst-lookup -qp chv.surweights.hfst
облаҫ	облаҫ	9,977600
```

The next thing we need to do is add a path in the weight transducer for unknown words (those 
words that are not found in the corpus). This should be the maximum weight of any word in the 
transducer. 

```
$ echo "?::0" | hfst-regexp2fst | hfst-repeat | hfst-reweight -e -a 15.0 | hfst-minimise -o chv.maxweight.hfst
```

Then we union the max weight transducer with the surface weights:

```
$ hfst-union -1 chv.surweights.hfst -2 chv.maxweight.hfst -o chv.weights.hfst
```
And compose this all with the surface side of the generator:
```
$ hfst-compose -1 chv.gen.hfst -2 chv.weights.hfst -o chv.gen_weighted.hfst
```

<!--

$ oovweight=`echo "-l(0.9/$total)" | bc -l`
$ echo "?::$oovweight" | hfst-regexp2fst | hfst-repeat -o chv.maxweight.hfst
$ hfst-union -1 chv.prob.hfst -2 chv.maxweight.hfst -o chv.weights.hfst
$ hfst-compose -1 chv.gen.hfst -2 chv.weights.hfst -o chv.weighted.hfst
-->



## Analyses 

<!-- TODO: examples -->

Let's imagine for a second that we have a massive gold standard annotated corpus of Guaraní. We could use 
that to assign different weights to the different analyses of our surface forms. For example our generator
might look like:
```
$ hfst-fst2strings grn.lexc.hfst 
jagua<n>:jagua
ja<n><gen>:jagua
```

Let's say that we saw *jagua* as "dog" 150 times in our corpus and *jagua* as "of the occasion" 3 times.
It would be fairly straightforward to write a Python script to convert these into a file with weights:

```
jagua<n>:jagua 0.0198
ja<n><gen>:jagua 3.9318
```

Remember we define weights as negative log probabilities, e.g. <math>w = -log(r)</math> where *r* is the
relative frequency in the corpus.

**Note:** You will need to make the file `grn.weights`, it should look like the example above.

```
$ cat grn.weights | hfst-strings2fst -j -m grn.symbols -o grn.strweights.hfst
$ echo "?::5.13579" | hfst-regexp2fst | hfst-repeat -o grn.maxweight.hfst
$ hfst-union -1 grn.strweights.hfst -2 grn.maxweight.hfst -o grn.weights.hfst
```

The file `grn.symbols` is a file with a list of all of the multicharacter symbols (e.g. `&lt;n&gt;`) specified
one per line, e.g.

```
$ cat grn.symbols
<n>
<gen>
```

```
$ hfst-invert grn.lexc.hfst | hfst-compose -2 grn.weights.hfst | hfst-invert | hfst-fst2txt
```

